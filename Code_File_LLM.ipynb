{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61247,"databundleVersionId":8550470,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2024-06-16T01:59:06.970441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport os\nimport sys\nimport random\nsys.path.append('../input/llm-20-questions/llm_20_questions/')\nimport keywords\nfrom kaggle_environments import make","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_colwidth', None)\nmy_json = json.loads(keywords.KEYWORDS_JSON)\njson_country = my_json[0]\njson_city = my_json[1]\njson_landmark = my_json[2]\nimport pprint\n\npprint.pprint(json_country['words'][:5])\npprint.pprint(json_city['words'][:5])\npprint.pprint(json_landmark['words'][:5])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_country = pd.json_normalize(json_country['words'])\ndf_city = pd.json_normalize(json_city['words'])\ndf_landmark = pd.json_normalize(json_landmark['words'])\nprint(df_country.head())\nprint(df_city.head())\nprint(df_landmark.head())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine all keywords into a single list\nall_keywords = (\n    list(df_country) +\n    list(df_city) +\n    list(df_landmark)\n)\ndf = pd.DataFrame(all_keywords)\n# Select 20 random keywords for questions\nrandom_keywords = df.sample()\nrandom_keywords","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the agent function using the dataframes\nclass AgentWithQuestions:\n    def __init__(self, df_country, df_city, df_landmark, questions):\n        self.df_country = df_country\n        self.df_city = df_city\n        self.df_landmark = df_landmark\n        self.questions = questions\n        self.question_index = 0\n\n    def __call__(self, obs, cfg):\n        if obs.turnType == \"ask\":\n            if self.question_index < len(self.questions):\n                response = self.questions[self.question_index]\n                print(f\"Agent asks: {response}\")\n                self.question_index += 1\n            else:\n                response = \"Is it a duck?\"  # Fallback question if we run out\n                print(f\"Agent asks: {response}\")\n        elif obs.turnType == \"guess\":\n            response = \"country\"  # Implement more complex guessing logic here\n            print(f\"Agent guesses: {response}\")\n        elif obs.turnType == \"answer\":\n            entity = obs.entity.lower()\n            if entity in self.df_country['word'].values:\n                response = \"country\"\n            elif entity in self.df_city['word'].values:\n                response = \"city\"\n            elif entity in self.df_landmark['word'].values:\n                response = \"landmark\"\n            else:\n                response = \"no\"\n            print(f\"Agent answers: {response} to entity {entity}\")\n        return response","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize the agent\nagent_instance = AgentWithQuestions(df_country, df_city, df_landmark, random_keywords)\n\n# Define agent function wrapper\ndef agent_fn(obs, cfg):\n    return agent_instance(obs, cfg)\n\n# Configuration for the environment\ndebug_config = {\n    'episodeSteps': 61,    # initial step plus 3 steps per round (ask/answer/guess)\n    'actTimeout': 60,      # agent time per round in seconds; default is 60\n    'runTimeout': 1200,    # max time for the episode in seconds; default is 1200\n    'agentTimeout': 3600   # obsolete field; default is 3600\n}\n\n# Initialize the environment\nenv = make(environment=\"llm_20_questions\", configuration=debug_config, debug=True)\n\n# Run the game\ngame_output = env.run(agents=[agent_fn, agent_fn, agent_fn, agent_fn])\n\n# Render the game output\nenv.render(mode=\"ipython\", width=1080, height=700)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}